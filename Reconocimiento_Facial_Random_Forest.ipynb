{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55c6407",
   "metadata": {},
   "source": [
    "# Reconocimiento Facial usando Random Forest\n",
    "\n",
    "Se entrena el clasificador Random Forest para reconocer imágenes de una base de datos de imágenes de video. \n",
    "Se usa el detector de rostros haarcascades en la librería de OpenCV para reconocer rostro en real time.\n",
    "Los resultados son excelentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7c144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2466046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: César S. Hooper/ Dic 2021\n",
      "\n",
      "matplotlib: 3.3.4\n",
      "seaborn   : 0.11.1\n",
      "sklearn   : 0.24.1\n",
      "cv2       : 4.5.4-dev\n",
      "numpy     : 1.19.5\n",
      "skimage   : 0.18.1\n",
      "pandas    : 1.2.4\n",
      "\n",
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "# Versiones de los paquetes usados en este notebook\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"César S. Hooper/ Dic 2021\" --iversions\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451315d",
   "metadata": {},
   "source": [
    "Para el entrenamiento usamos las imágenes con las que entrenamos un modelo de reconocimiento facial con OpenCV.\n",
    "Dejo el link\n",
    "https://github.com/hoopercesar/Reconocimiento_facial/blob/main/Reconocimiento_Facial_con_OpenCV.ipynb\n",
    "\n",
    "Estas imágenes fueron extraídas de dos registros de video, se guardaron en formato jpg con tamaño 100x100 pixeles con los tres canales BGR. \n",
    "\n",
    "### Preparración de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f17ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las imágenes 321 imágenes de cada archivo, las transformamos al gris \n",
    "# y las guardamos en una lista como array de 100x100. \n",
    "# En total serán 642 matrices de con datos en formato de imagen dtype='uint8'\n",
    "\n",
    "directorios = ['cesar', 'fernanda']\n",
    "path = 'C:/Users/Cesar Hooper/Desktop/github/reconocimiento_facial/data/'\n",
    "lista = []\n",
    "for directorio in directorios:\n",
    "    counter = 0\n",
    "    persona = path + directorio\n",
    "    for foto in os.listdir(persona):\n",
    "        \n",
    "        while counter<=320:\n",
    "            img = cv2.imread(persona + '/' + foto)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            lista.append(img)\n",
    "            counter += 1\n",
    "# tranformar la lista en array\n",
    "x = np.array(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538c9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cada matriz (100x100) se transforma en un un array de 1 fila por 10000 columnas\n",
    "# por tanto, x será un array de 642 vectores de 10000 columnas\n",
    "\n",
    "x = x.reshape(-1,10000) # este es un array de (642, 10000)\n",
    "\n",
    "# creamos diccionario y luego dataframe\n",
    "s = {}\n",
    "for columna in range(x.shape[1]):\n",
    "    s['p'+str(columna)] = list(x[:,columna])\n",
    "\n",
    "dataframe = pd.DataFrame(s)    \n",
    "\n",
    "# crear labels\n",
    "k = np.arange(2)\n",
    "labels = np.repeat(k, dataframe.shape[0]/2)\n",
    "\n",
    "dataframe['target'] = labels\n",
    "\n",
    "# randomizamos las filas del dataframe\n",
    "dataframe_random = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "y = dataframe_random['target']\n",
    "X = dataframe_random.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c02b5",
   "metadata": {},
   "source": [
    "### Creación y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90cbbe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.00000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8) # 70% training and 30% test\n",
    "\n",
    "#Crea el Classifier\n",
    "clf=RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Entrena el modelo y luego usa y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:%.5f\"%metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72cf8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "faceclassif = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    auxframe = gray.copy()\n",
    "    \n",
    "    faces = faceclassif.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for faz in faces:\n",
    "        x,y,h,w = faz\n",
    "        rostro = auxframe[y:y+h, x:x+w]\n",
    "        rostro = cv2.resize(rostro, (100,100), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        z = rostro.reshape(-1, 10000)\n",
    "        dataframe = pd.DataFrame(z)\n",
    "            \n",
    "       \n",
    "        resultado = clf.predict(dataframe)\n",
    "        prob = clf.predict_proba(dataframe)\n",
    "        #print(prob)\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "                \n",
    "        if resultado == 0:\n",
    "            cv2.putText(frame, '{}'.format('Cesar ,' + str(prob[0][0])), (x,y-5), 1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
    "        elif resultado == 1:\n",
    "            cv2.putText(frame, '{}'.format('Fer'), (x,y-5), 1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, '{}'.format('desconocido'), (x,y-5), 1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27: break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39ae35",
   "metadata": {},
   "source": [
    "### Comentarios\n",
    "\n",
    "El modelo reconoce relativamente bien los rostros, con alrededor de un 70% de certeza. \n",
    "El modelaje de imágenes y el entrenamiento de modelos de reconocimiento depende sensiblemente de la luz\n",
    "y el contraste de las imágenes, por tanto, la capacidad del modelo, para reconocer una imagen, depende \n",
    "de estos parámetros. \n",
    "Es recomendable usar más imágenes para el entrenamiento. Se usaron 640 imagenes en este notebook, lo que es poco.\n",
    "Pero este es sólo un estudio preliminar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65683d81",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
